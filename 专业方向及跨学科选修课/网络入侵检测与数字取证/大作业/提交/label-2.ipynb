{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 初始化\n",
    "## 1.1 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 读入文件\n",
    "\n",
    "存放在 list 中\n",
    "\n",
    "### 1.2.1 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_l_fqdn = []\n",
    "with open('5_question_train/fqdn.csv', 'r', encoding='utf-8') as f:\n",
    "    f_fqdn = csv.reader(f)\n",
    "    headers = next(f_fqdn)\n",
    "    for row in f_fqdn:\n",
    "        TRAIN_l_fqdn.append(row)\n",
    "\n",
    "TRAIN_l_ip = {}\n",
    "with open('5_question_train/ip.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ip = csv.reader(f)\n",
    "    headers = next(f_ip)\n",
    "    for row in f_ip:\n",
    "        TRAIN_l_ip[row[0]] = row[1:]\n",
    "\n",
    "# l_ipv6 = []\n",
    "with open('5_question_train/ipv6.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ipv6 = csv.reader(f)\n",
    "    headers = next(f_ipv6)\n",
    "    for row in f_ipv6:\n",
    "        # l_ipv6[row[0]] = row[1:]\n",
    "        TRAIN_l_ip[row[0]] = row[1:]\n",
    "\n",
    "TRAIN_l_access = []\n",
    "with open('5_question_train/access.csv', 'r', encoding='utf-8') as f:\n",
    "    f_access = csv.reader(f)\n",
    "    headers = next(f_access)\n",
    "    for row in f_access:\n",
    "        TRAIN_l_access.append(row)\n",
    "\n",
    "TRAIN_l_flint = []\n",
    "with open('5_question_train/flint.csv', 'r', encoding='utf-8') as f:\n",
    "    f_flint = csv.reader(f)\n",
    "    headers = next(f_flint)\n",
    "    for row in f_flint:\n",
    "        TRAIN_l_flint.append(row)\n",
    "\n",
    "TRAIN_l_label = []\n",
    "with open('5_question_train/label.csv', 'r', encoding='utf-8') as f:\n",
    "    f_label = csv.reader(f)\n",
    "    headers = next(f_label)\n",
    "    for row in f_label:\n",
    "        TRAIN_l_label.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_l_fqdn = []\n",
    "with open('5_question_test/fqdn.csv', 'r', encoding='utf-8') as f:\n",
    "    f_fqdn = csv.reader(f)\n",
    "    headers = next(f_fqdn)\n",
    "    for row in f_fqdn:\n",
    "        TEST_l_fqdn.append(row)\n",
    "\n",
    "TEST_l_ip = {}\n",
    "with open('5_question_test/ip.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ip = csv.reader(f)\n",
    "    headers = next(f_ip)\n",
    "    for row in f_ip:\n",
    "        TEST_l_ip[row[0]] = row[1:]\n",
    "\n",
    "# l_ipv6 = []\n",
    "with open('5_question_test/ipv6.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ipv6 = csv.reader(f)\n",
    "    headers = next(f_ipv6)\n",
    "    for row in f_ipv6:\n",
    "        # l_ipv6[row[0]] = row[1:]\n",
    "        TEST_l_ip[row[0]] = row[1:]\n",
    "\n",
    "TEST_l_access = []\n",
    "with open('5_question_test/access.csv', 'r', encoding='utf-8') as f:\n",
    "    f_access = csv.reader(f)\n",
    "    headers = next(f_access)\n",
    "    for row in f_access:\n",
    "        TEST_l_access.append(row)\n",
    "\n",
    "TEST_l_flint = []\n",
    "with open('5_question_test/flint.csv', 'r', encoding='utf-8') as f:\n",
    "    f_flint = csv.reader(f)\n",
    "    headers = next(f_flint)\n",
    "    for row in f_flint:\n",
    "        TEST_l_flint.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 训练集特征提取\n",
    "\n",
    "## 2.1 access\n",
    "\n",
    "将 access 与 ip 一并处理。选取的特征有\n",
    "\n",
    "- 访问次数\n",
    "- 连续访问次数\n",
    "- 访问 IP 数\n",
    "- 按小时统计访问次数\n",
    "- 按日期统计访问次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "tot_fqdn = 20512 # fqdn 编号总数\n",
    "\n",
    "l_accesscount = [0] * tot_fqdn # 访问次数\n",
    "l_multiaccesscount = [0] * tot_fqdn # 多次访问次数\n",
    "# l_multiaccessip = [set() for _ in range(tot_fqdn)] # 多次访问IP\n",
    "l_accesstime = [[0] * 24 for _ in range(tot_fqdn)] # 按小时统计访问次数\n",
    "l_accessdate = [[0] * 92 for _ in range(tot_fqdn)] # 按日期统计访问次数\n",
    "l_accessip = [0] * tot_fqdn  # 访问IP数\n",
    "\n",
    "date2 = date(2020, 3, 1) # 开始日期\n",
    "\n",
    "# count\n",
    "\n",
    "for access in TRAIN_l_access:\n",
    "    num = int(access[0][5:]) # 域名编号\n",
    "    access_ip = int(access[1]) # 访问IP数\n",
    "    access_count = int(access[2]) # 访问次数\n",
    "    access_date = access[4] # 访问日期\n",
    "    access_hour = int(access[5]) # 访问时间\n",
    "\n",
    "    l_accesscount[num] += access_count # 编号为 num 的域名的访问次数\n",
    "    if access_count > 1:\n",
    "        l_multiaccesscount[num] += access_count  # 编号为 num 的域名的连续访问次数\n",
    "        # l_multiaccessip[num].add(access_ip) # 编号为 num 的域名的连续访问 IP\n",
    "\n",
    "    l_accesstime[num][access_hour] += access_count  # 编号为 num 的域名按小时统计时间段的访问次数\n",
    "\n",
    "    date1 = datetime.datetime.strptime(access_date, '%Y%m%d').date()\n",
    "    l_accessdate[num][(date1 - date2).days] += access_count  # 编号为 num 的域名按日期统计访问次数\n",
    "\n",
    "    l_accessip[num] += access_ip  # 编号为 num 的域名的访问 IP 数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 flint\n",
    "\n",
    "选取的特征有\n",
    "\n",
    "- 解析次数\n",
    "- 按日期统计解析次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_notip = [] # 解析结果不是 IP 的域名\n",
    "\n",
    "l_flintcount = [0] * tot_fqdn # 解析次数\n",
    "l_flintdate = [[0] * 92 for _ in range(tot_fqdn)] # 按日期统计解析次数\n",
    "\n",
    "for flint in TRAIN_l_flint:\n",
    "    num = int(flint[0][5:])  # 域名编号\n",
    "    typenum = int(flint[1])  # 域名类型\n",
    "    if flint[2][0:4] == 'fqdn':\n",
    "        refernum = int(flint[2][5:]) # 域名引用编号\n",
    "        count = int(flint[3]) # 域名引用访问次数\n",
    "        date = datetime.datetime.strptime(flint[4], '%Y%m%d').date() # 域名引用访问时间\n",
    "        l_notip.append([num, typenum, refernum, count, date])\n",
    "    else:\n",
    "        ip = flint[2]  # 域名 IP\n",
    "        count = int(flint[3])  # 域名访问次数\n",
    "        date = datetime.datetime.strptime(flint[4], '%Y%m%d').date()  # 域名访问时间\n",
    "        \n",
    "    \n",
    "    l_flintcount[num] += count # 编号为 num 的域名的解析次数\n",
    "    l_flintdate[num][(date - date2).days] += count # 编号为 num 的域名按日期统计解析次数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 label\n",
    "\n",
    "提取标签，并为拆分训练集、测试集做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_all = [-1] * tot_fqdn # 域名标签\n",
    "\n",
    "for label in TRAIN_l_label:\n",
    "    num = int(label[0][5:])  # 域名编号\n",
    "    Label_all[num] = int(label[1])  # 域名标签\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 fqdn\n",
    "\n",
    "进一步处理 2.1 - 2.3 得到的内容。\n",
    "\n",
    "提取 fqdn 中的特征：\n",
    "\n",
    "- 字符个数\n",
    "- 数字个数\n",
    "- 普通字符个数\n",
    "- 特殊字符个数\n",
    "- 单词字母个数\n",
    "- 深度\n",
    "\n",
    "并将所有内容整合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_num =[] # 训练集域名编号\n",
    "TRAIN_feature = []  # 合并信息\n",
    "TRAIN_label = []  # 域名标签\n",
    "\n",
    "for fqdn in TRAIN_l_fqdn:\n",
    "    url = fqdn[0] # 域名\n",
    "    num = int(fqdn[1][5:]) # 域名编号\n",
    "\n",
    "    n_character = 0 # 字符个数\n",
    "    n_digit = 0 # 数字个数\n",
    "    n_normal = 0 # 普通字符个数\n",
    "    n_special = 0 # 特殊字符个数\n",
    "    n_alpha = 0 # 单词字母个数\n",
    "    n_depth = 0 # 深度\n",
    "    \n",
    "    n_access = l_accesscount[num] # 访问次数\n",
    "    n_multiaccess = l_multiaccesscount[num] # 连续访问次数\n",
    "    n_access_ip = l_accessip[num] # 访问 IP 数\n",
    "    n_access_byhour = l_accesstime[num]  # 按小时统计访问次数\n",
    "    n_access_bydate = l_accessdate[num]  # 按日期统计访问次数\n",
    "\n",
    "    n_flint = l_flintcount[num] # 解析次数\n",
    "    n_flint_bydate = l_flintdate[num] # 按日期统计解析次数\n",
    "\n",
    "    is_normal_suffix = 0 # 是否是普通后缀\n",
    "    commonRootList = ['cn', 'com', 'net', 'org', 'gov', 'info', 'edu']\n",
    "    if url.split('.')[-1] in commonRootList:\n",
    "        is_normal_suffix = 1\n",
    "\n",
    "    is_alpha = False # 是否为单词字母\n",
    "\n",
    "    for i in range(len(url)):\n",
    "        if url[i] == '[':\n",
    "            is_alpha = True\n",
    "        elif url[i] == ']':\n",
    "            is_alpha = False\n",
    "        else:\n",
    "            n_character += 1\n",
    "            \n",
    "            if url[i].isalnum():\n",
    "                n_normal += 1\n",
    "            else:\n",
    "                n_special += 1\n",
    "\n",
    "            if url[i].isdigit():\n",
    "                n_digit += 1\n",
    "\n",
    "            if is_alpha:\n",
    "                n_alpha += 1\n",
    "                \n",
    "            if url[i] == '.':\n",
    "                n_depth += 1\n",
    "    \n",
    "    tmp = [n_character, n_digit, n_normal, n_special, n_alpha, n_depth, is_normal_suffix,\n",
    "           n_access, n_multiaccess, n_access_ip,\n",
    "           n_flint]\n",
    "    tmp.extend(n_access_byhour)\n",
    "    tmp.extend(n_access_bydate)\n",
    "    tmp.extend(n_flint_bydate)\n",
    "    if Label_all[num] != -1:\n",
    "        TRAIN_num.append(num)\n",
    "        TRAIN_feature.append(tmp)\n",
    "        TRAIN_label.append(Label_all[num])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 测试集特征提取\n",
    "\n",
    "## 3.1 access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "tot_fqdn = 20512  # fqdn 编号总数\n",
    "\n",
    "l_accesscount = [0] * tot_fqdn  # 访问次数\n",
    "l_multiaccesscount = [0] * tot_fqdn  # 多次访问次数\n",
    "# l_multiaccessip = [set() for _ in range(tot_fqdn)] # 多次访问IP\n",
    "l_accesstime = [[0] * 24 for _ in range(tot_fqdn)]  # 按小时统计访问次数\n",
    "l_accessdate = [[0] * 92 for _ in range(tot_fqdn)]  # 按日期统计访问次数\n",
    "l_accessip = [0] * tot_fqdn  # 访问IP数\n",
    "\n",
    "# count\n",
    "\n",
    "for access in TEST_l_access:\n",
    "    num = int(access[0][5:])  # 域名编号\n",
    "    access_ip = int(access[1])  # 访问IP数\n",
    "    access_count = int(access[2])  # 访问次数\n",
    "    access_date = access[4]  # 访问日期\n",
    "    access_hour = int(access[5])  # 访问时间\n",
    "\n",
    "    l_accesscount[num] += access_count  # 编号为 num 的域名的访问次数\n",
    "    if access_count > 1:\n",
    "        l_multiaccesscount[num] += access_count  # 编号为 num 的域名的连续访问次数\n",
    "        # l_multiaccessip[num].add(access_ip) # 编号为 num 的域名的连续访问 IP\n",
    "\n",
    "    l_accesstime[num][access_hour] += access_count  # 编号为 num 的域名按小时统计时间段的访问次数\n",
    "\n",
    "    date1 = datetime.datetime.strptime(access_date, '%Y%m%d').date()\n",
    "    # 编号为 num 的域名按日期统计访问次数\n",
    "    l_accessdate[num][(date1 - date2).days] += access_count\n",
    "\n",
    "    l_accessip[num] += access_ip  # 编号为 num 的域名的访问 IP 数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 flint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_notip = []  # 解析结果不是 IP 的域名\n",
    "\n",
    "l_flintcount = [0] * tot_fqdn  # 解析次数\n",
    "l_flintdate = [[0] * 92 for _ in range(tot_fqdn)]  # 按日期统计解析次数\n",
    "\n",
    "for flint in TEST_l_flint:\n",
    "    num = int(flint[0][5:])  # 域名编号\n",
    "    typenum = int(flint[1])  # 域名类型\n",
    "    if flint[2][0:4] == 'fqdn':\n",
    "        refernum = int(flint[2][5:])  # 域名引用编号\n",
    "        count = int(flint[3])  # 域名引用访问次数\n",
    "        date = datetime.datetime.strptime(\n",
    "            flint[4], '%Y%m%d').date()  # 域名引用访问时间\n",
    "        l_notip.append([num, typenum, refernum, count, date])\n",
    "    else:\n",
    "        ip = flint[2]  # 域名 IP\n",
    "        count = int(flint[3])  # 域名访问次数\n",
    "        date = datetime.datetime.strptime(flint[4], '%Y%m%d').date()  # 域名访问时间\n",
    "\n",
    "    l_flintcount[num] += count  # 编号为 num 的域名的解析次数\n",
    "    l_flintdate[num][(date - date2).days] += count  # 编号为 num 的域名按日期统计解析次数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 fqdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_num =[] # 训练集域名编号\n",
    "TEST_feature = []  # 合并信息\n",
    "TEST_label = []  # 域名标签\n",
    "\n",
    "for fqdn in TEST_l_fqdn:\n",
    "    url = fqdn[0] # 域名\n",
    "    num = int(fqdn[1][5:]) # 域名编号\n",
    "\n",
    "    n_character = 0 # 字符个数\n",
    "    n_digit = 0 # 数字个数\n",
    "    n_normal = 0 # 普通字符个数\n",
    "    n_special = 0 # 特殊字符个数\n",
    "    n_alpha = 0 # 单词字母个数\n",
    "    n_depth = 0 # 深度\n",
    "    \n",
    "    n_access = l_accesscount[num] # 访问次数\n",
    "    n_multiaccess = l_multiaccesscount[num] # 连续访问次数\n",
    "    n_access_ip = l_accessip[num] # 访问 IP 数\n",
    "    n_access_byhour = l_accesstime[num]  # 按小时统计访问次数\n",
    "    n_access_bydate = l_accessdate[num]  # 按日期统计访问次数\n",
    "\n",
    "    n_flint = l_flintcount[num] # 解析次数\n",
    "    n_flint_bydate = l_flintdate[num] # 按日期统计解析次数\n",
    "\n",
    "    is_normal_suffix = 0 # 是否是普通后缀\n",
    "    commonRootList = ['cn', 'com', 'net', 'org', 'gov', 'info', 'edu']\n",
    "    if url.split('.')[-1] in commonRootList:\n",
    "        is_normal_suffix = 1\n",
    "\n",
    "    is_alpha = False # 是否为单词字母\n",
    "\n",
    "    for i in range(len(url)):\n",
    "        if url[i] == '[':\n",
    "            is_alpha = True\n",
    "        elif url[i] == ']':\n",
    "            is_alpha = False\n",
    "        else:\n",
    "            n_character += 1\n",
    "            \n",
    "            if url[i].isalnum():\n",
    "                n_normal += 1\n",
    "            else:\n",
    "                n_special += 1\n",
    "\n",
    "            if url[i].isdigit():\n",
    "                n_digit += 1\n",
    "\n",
    "            if is_alpha:\n",
    "                n_alpha += 1\n",
    "                \n",
    "            if url[i] == '.':\n",
    "                n_depth += 1\n",
    "    \n",
    "    tmp = [n_character, n_digit, n_normal, n_special, n_alpha, n_depth, is_normal_suffix,\n",
    "           n_access, n_multiaccess, n_access_ip,\n",
    "           n_flint]\n",
    "    tmp.extend(n_access_byhour)\n",
    "    tmp.extend(n_access_bydate)\n",
    "    tmp.extend(n_flint_bydate)\n",
    "    TEST_num.append(num)\n",
    "    TEST_feature.append(tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 训练与预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:47:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "params = { # 玄学调参\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.05,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# 构造训练集\n",
    "dtrain = xgb.DMatrix(TRAIN_feature, TRAIN_label)\n",
    "num_rounds = 5000\n",
    "# xgboost模型训练\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 对测试集进行预测\n",
    "dtest = xgb.DMatrix(TEST_feature)\n",
    "TEST_label = model.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出结果\n",
    "with open(\"result2.csv\", \"w\") as csvfile:\n",
    "    csvfile.write(\"fqdn_no,label\\n\")\n",
    "    for i in range(len(TEST_num)):\n",
    "        csvfile.write(\"fqdn_\" + str(TEST_num[i]) + \",\" + str(round(TEST_label[i])) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
