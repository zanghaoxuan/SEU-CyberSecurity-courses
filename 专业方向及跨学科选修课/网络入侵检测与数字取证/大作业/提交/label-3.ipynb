{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 初始化\n",
    "## 1.1 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "from datetime import date, datetime\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 读入文件\n",
    "\n",
    "存放在 list 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_l_fqdn = []\n",
    "with open('fqdn.csv', 'r', encoding='utf-8') as f:\n",
    "    f_fqdn = csv.reader(f)\n",
    "    headers = next(f_fqdn) # 跳过第一行\n",
    "    for row in f_fqdn:\n",
    "        TRAIN_l_fqdn.append(row)\n",
    "\n",
    "TRAIN_l_ip = {}\n",
    "with open('ip.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ip = csv.reader(f)\n",
    "    headers = next(f_ip)\n",
    "    for row in f_ip:\n",
    "        TRAIN_l_ip[row[0]] = row[1:]\n",
    "\n",
    "# TRAIN_l_ipv6 = []\n",
    "with open('ipv6.csv', 'r', encoding='utf-8') as f:\n",
    "    f_ipv6 = csv.reader(f)\n",
    "    headers = next(f_ipv6)\n",
    "    for row in f_ipv6:\n",
    "        # TRAIN_l_ipv6[row[0]] = row[1:]\n",
    "        TRAIN_l_ip[row[0]] = row[1:]\n",
    "\n",
    "TRAIN_l_access = []\n",
    "with open('access.csv', 'r', encoding='utf-8') as f:\n",
    "    f_access = csv.reader(f)\n",
    "    headers = next(f_access)\n",
    "    for row in f_access:\n",
    "        TRAIN_l_access.append(row)\n",
    "\n",
    "TRAIN_l_flint = []\n",
    "with open('flint.csv', 'r', encoding='utf-8') as f:\n",
    "    f_flint = csv.reader(f)\n",
    "    headers = next(f_flint)\n",
    "    for row in f_flint:\n",
    "        TRAIN_l_flint.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 特征提取\n",
    "\n",
    "## 2.1 access\n",
    "\n",
    "将 access 与 ip 一并处理。选取的特征有\n",
    "\n",
    "- 访问次数\n",
    "- 连续访问次数\n",
    "- 访问 IP 数\n",
    "- 访问国家数\n",
    "- 访问城市数\n",
    "- 访问 ISP 数\n",
    "- 按小时统计访问次数\n",
    "- 按日期统计访问次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "tot_fqdn = 17468  # fqdn 编号总数\n",
    "\n",
    "l_accesscount = [0] * tot_fqdn  # 访问次数\n",
    "l_multiaccesscount = [0] * tot_fqdn  # 多次访问次数\n",
    "l_multiaccessip = [set() for _ in range(tot_fqdn)] # 多次访问IP\n",
    "l_accesstime = [[0] * 24 for _ in range(tot_fqdn)]  # 按小时统计访问次数\n",
    "l_accessdate = [[0] * 92 for _ in range(tot_fqdn)]  # 按日期统计访问次数\n",
    "l_accessip = [set() for _ in range(tot_fqdn)]  # 访问IP\n",
    "l_ipcountry = [set() for _ in range(tot_fqdn)]  # 访问IP所在国家\n",
    "l_ipcity = [set() for _ in range(tot_fqdn)]  # 访问IP所在城市\n",
    "l_ipisp = [set() for _ in range(tot_fqdn)]  # 访问IP ISP\n",
    "\n",
    "date2 = date(2020, 3, 1)  # 开始日期\n",
    "\n",
    "# count\n",
    "\n",
    "for access in TRAIN_l_access:\n",
    "    num = int(access[0][5:])  # 域名编号\n",
    "    access_ip = access[1]  # 访问IP\n",
    "    access_count = int(access[2])  # 访问次数\n",
    "    access_date = access[4]  # 访问日期\n",
    "    access_hour = int(access[5])  # 访问时间\n",
    "\n",
    "    l_accesscount[num] += access_count  # 编号为 num 的域名的访问次数\n",
    "    if access_count > 1:\n",
    "        l_multiaccesscount[num] += access_count  # 编号为 num 的域名的连续访问次数\n",
    "        l_multiaccessip[num].add(access_ip) # 编号为 num 的域名的连续访问 IP\n",
    "\n",
    "    l_accesstime[num][access_hour] += access_count  # 编号为 num 的域名按小时统计时间段的访问次数\n",
    "\n",
    "    date1 = datetime.datetime.strptime(access_date, '%Y%m%d').date()\n",
    "    # 编号为 num 的域名按日期统计访问次数\n",
    "    l_accessdate[num][(date1 - date2).days] += access_count\n",
    "\n",
    "    match_ip = TRAIN_l_ip[access_ip]\n",
    "    l_accessip[num].add(access_ip)  # 编号为 num 的域名的访问 IP 列表\n",
    "    l_ipcountry[num].add(match_ip[0])  # 编号为 num 的域名的访问 IP 地址的国家列表\n",
    "    l_ipcity[num].add(match_ip[2])  # 编号为 num 的域名的访问 IP 地址的城市列表\n",
    "    l_ipisp[num].add(match_ip[5])  # 编号为 num 的域名的访问 IP 地址的 ISP 列表\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 flint\n",
    "\n",
    "选取的特征有\n",
    "\n",
    "- 解析次数\n",
    "- 按日期统计解析次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_notip = []  # 解析结果不是 IP 的域名\n",
    "\n",
    "l_flintcount = [0] * tot_fqdn  # 解析次数\n",
    "l_flintttl = [0] * tot_fqdn  # 解析 TTL\n",
    "l_flintdate = [[0] * 92 for _ in range(tot_fqdn)]  # 按日期统计解析次数\n",
    "\n",
    "for flint in TRAIN_l_flint:\n",
    "    num = int(flint[0][5:])  # 域名编号\n",
    "    typenum = int(flint[1])  # 域名类型\n",
    "    if flint[2][0:4] == 'fqdn':\n",
    "        refernum = int(flint[2][5:])  # 域名引用编号\n",
    "        count = int(flint[3])  # 域名引用访问次数\n",
    "        if flint[4] != '':\n",
    "            ttl = int(flint[4])  # 域名引用 TTL\n",
    "        else:\n",
    "            ttl = 0\n",
    "        date = datetime.datetime.strptime(flint[5], '%Y%m%d').date()  # 域名引用访问时间\n",
    "        l_notip.append([num, typenum, refernum, count, date])\n",
    "    else:\n",
    "        ip = flint[2]  # 域名 IP\n",
    "        count = int(flint[3])  # 域名访问次数\n",
    "        if flint[4] != '':\n",
    "            ttl = int(flint[4])  # 域名引用 TTL\n",
    "        else:\n",
    "            ttl = 0\n",
    "        date = datetime.datetime.strptime(flint[5], '%Y%m%d').date()  # 域名访问时间\n",
    "\n",
    "    l_flintcount[num] += count  # 编号为 num 的域名的解析次数\n",
    "    l_flintttl[num] += ttl  # 编号为 num 的域名的解析 TTL\n",
    "    l_flintdate[num][(date - date2).days] += count  # 编号为 num 的域名按日期统计解析次数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 fqdn\n",
    "\n",
    "进一步处理 2.1 - 2.4 得到的内容。\n",
    "\n",
    "提取 fqdn 中的特征：\n",
    "\n",
    "- 字符个数\n",
    "- 数字个数\n",
    "- 普通字符个数\n",
    "- 特殊字符个数\n",
    "- 单词字母个数\n",
    "- 深度\n",
    "\n",
    "并将所有内容整合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_num = []  # 训练集域名编号\n",
    "TRAIN_feature = []  # 合并信息\n",
    "TRAIN_label = []  # 域名标签\n",
    "\n",
    "for fqdn in TRAIN_l_fqdn:\n",
    "    url = fqdn[0]  # 域名\n",
    "    num = int(fqdn[1][5:])  # 域名编号\n",
    "\n",
    "    n_character = 0  # 字符个数\n",
    "    n_digit = 0  # 数字个数\n",
    "    n_normal = 0  # 普通字符个数\n",
    "    n_special = 0  # 特殊字符个数\n",
    "    n_alpha = 0  # 单词字母个数\n",
    "    n_depth = 0  # 深度\n",
    "\n",
    "    n_access = l_accesscount[num]  # 访问次数\n",
    "    n_multiaccess = l_multiaccesscount[num]  # 连续访问次数\n",
    "    n_access_ip = len(l_accessip[num])  # 访问 IP 数\n",
    "    n_access_country = len(l_ipcountry[num])  # 访问国家数\n",
    "    n_access_city = len(l_ipcity[num])  # 访问城市数\n",
    "    n_access_isp = len(l_ipisp[num])  # 访问 ISP 数\n",
    "    n_access_byhour = l_accesstime[num]  # 按小时统计访问次数\n",
    "    n_access_bydate = l_accessdate[num]  # 按日期统计访问次数\n",
    "\n",
    "    n_flint = l_flintcount[num]  # 解析次数\n",
    "    n_flint_bydate = l_flintdate[num]  # 按日期统计解析次数\n",
    "\n",
    "    is_normal_suffix = 0  # 是否是普通后缀\n",
    "    commonRootList = ['cn', 'com', 'net', 'org', 'gov', 'info', 'edu']\n",
    "    if url.split('.')[-1] in commonRootList:\n",
    "        is_normal_suffix = 1\n",
    "\n",
    "    is_alpha = False  # 是否为单词字母\n",
    "\n",
    "    for i in range(len(url)):\n",
    "        if url[i] == '[':\n",
    "            is_alpha = True\n",
    "        elif url[i] == ']':\n",
    "            is_alpha = False\n",
    "        else:\n",
    "            n_character += 1\n",
    "\n",
    "            if url[i].isalnum():\n",
    "                n_normal += 1\n",
    "            else:\n",
    "                n_special += 1\n",
    "\n",
    "            if url[i].isdigit():\n",
    "                n_digit += 1\n",
    "\n",
    "            if is_alpha:\n",
    "                n_alpha += 1\n",
    "\n",
    "            if url[i] == '.':\n",
    "                n_depth += 1\n",
    "\n",
    "    tmp = [n_character, n_digit, n_normal, n_special, n_alpha, n_depth, is_normal_suffix,\n",
    "           n_access, n_multiaccess, n_access_ip, n_access_country, n_access_city, n_access_isp,\n",
    "           n_flint]\n",
    "\n",
    "    tmp.append(min(n_access_byhour))\n",
    "    tmp.append(n_access_byhour.index(min(n_access_byhour)))\n",
    "    tmp.append(max(n_access_byhour))\n",
    "    tmp.append(n_access_byhour.index(max(n_access_byhour)))\n",
    "    # tmp.append(statistics.mean(n_access_byhour))\n",
    "    tmp.append(statistics.median(n_access_byhour))\n",
    "    tmp.append(statistics.pstdev(n_access_byhour))\n",
    "\n",
    "    tmp.append(min(n_access_bydate))\n",
    "    tmp.append(n_access_bydate.index(min(n_access_bydate)))\n",
    "    tmp.append(max(n_access_bydate))\n",
    "    tmp.append(n_access_bydate.index(max(n_access_bydate)))\n",
    "    # tmp.append(statistics.mean(n_access_bydate))\n",
    "    tmp.append(statistics.median(n_access_bydate))\n",
    "    tmp.append(statistics.pstdev(n_access_bydate))\n",
    "    \n",
    "    tmp.append(min(n_flint_bydate))\n",
    "    tmp.append(n_flint_bydate.index(min(n_flint_bydate)))\n",
    "    tmp.append(max(n_flint_bydate))\n",
    "    tmp.append(n_flint_bydate.index(max(n_flint_bydate)))\n",
    "    # tmp.append(statistics.mean(n_flint_bydate))\n",
    "    tmp.append(statistics.median(n_flint_bydate))\n",
    "    tmp.append(statistics.pstdev(n_flint_bydate))\n",
    "    \n",
    "    TRAIN_feature.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_num = []  # 训练集域名编号\n",
    "TRAIN_feature = []  # 合并信息\n",
    "TRAIN_label = []  # 域名标签\n",
    "\n",
    "for fqdn in TRAIN_l_fqdn:\n",
    "    url = fqdn[0]  # 域名\n",
    "    num = int(fqdn[1][5:])  # 域名编号\n",
    "\n",
    "    n_character = 0  # 字符个数\n",
    "    n_digit = 0  # 数字个数\n",
    "    n_normal = 0  # 普通字符个数\n",
    "    n_special = 0  # 特殊字符个数\n",
    "    n_alpha = 0  # 单词字母个数\n",
    "    n_depth = 0  # 深度\n",
    "\n",
    "    n_access = l_accesscount[num]  # 访问次数\n",
    "    n_multiaccess = l_multiaccesscount[num]  # 连续访问次数\n",
    "    n_access_ip = len(l_accessip[num])  # 访问 IP 数\n",
    "    n_access_country = len(l_ipcountry[num])  # 访问国家数\n",
    "    n_access_city = len(l_ipcity[num])  # 访问城市数\n",
    "    n_access_isp = len(l_ipisp[num])  # 访问 ISP 数\n",
    "    n_access_byhour = l_accesstime[num]  # 按小时统计访问次数\n",
    "    n_access_bydate = l_accessdate[num]  # 按日期统计访问次数\n",
    "\n",
    "    n_flint = l_flintcount[num]  # 解析次数\n",
    "    n_flint_bydate = l_flintdate[num]  # 按日期统计解析次数\n",
    "\n",
    "    is_normal_suffix = 0  # 是否是普通后缀\n",
    "    commonRootList = ['cn', 'com', 'net', 'org', 'gov', 'info', 'edu']\n",
    "    if url.split('.')[-1] in commonRootList:\n",
    "        is_normal_suffix = 1\n",
    "\n",
    "    is_alpha = False  # 是否为单词字母\n",
    "\n",
    "    for i in range(len(url)):\n",
    "        if url[i] == '[':\n",
    "            is_alpha = True\n",
    "        elif url[i] == ']':\n",
    "            is_alpha = False\n",
    "        else:\n",
    "            n_character += 1\n",
    "\n",
    "            if url[i].isalnum():\n",
    "                n_normal += 1\n",
    "            else:\n",
    "                n_special += 1\n",
    "\n",
    "            if url[i].isdigit():\n",
    "                n_digit += 1\n",
    "\n",
    "            if is_alpha:\n",
    "                n_alpha += 1\n",
    "\n",
    "            if url[i] == '.':\n",
    "                n_depth += 1\n",
    "\n",
    "    tmp = [n_character, n_digit, n_normal, n_special, n_alpha, n_depth, is_normal_suffix,\n",
    "           n_access, n_multiaccess, n_access_ip, n_access_country, n_access_city, n_access_isp,\n",
    "           n_flint]\n",
    "\n",
    "    tmp.extend(n_access_byhour)\n",
    "    tmp.extend(n_access_bydate)\n",
    "    tmp.extend(n_flint_bydate)\n",
    "    \n",
    "    TRAIN_feature.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.648149940873604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "TRAIN_feature_normalization = MinMaxScaler().fit_transform(TRAIN_feature)\n",
    "\n",
    "label_pred = KMeans(n_clusters=5).fit_predict(TRAIN_feature_normalization)\n",
    "\n",
    "calinski_harabasz_score(TRAIN_feature, label_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出结果\n",
    "with open(\"result2.csv\", \"w\") as csvfile:\n",
    "    csvfile.write(\"fqdn_no,label\\n\")\n",
    "    for i in range(len(label_pred)):\n",
    "        csvfile.write(\"fqdn_\" + str(i) + \",\" + str(label_pred[i]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5933, 1: 5752, 3: 2394, 2: 2165, 4: 1224})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "num_Count = Counter(label_pred)\n",
    "print(num_Count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
